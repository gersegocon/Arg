# -*- coding: utf-8 -*-
"""Evaluación 2 - 3° Tramo AP Analisis de datos

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-iqlJrl0pc3AZDX16CvqMR8h47IhDTXD

Zoo.csv
El archivo Zoo.csv contiene las características de 101 animales entre los que hay anfibios, aves, mamíferos, peces, insectos, invertebrados y reptiles. Marque como “id” el atributo “animal” y como “label” el atributo “clase”. Agrupe los datos  utilizando el algoritmo K-means sin considerar los atributos “animal” y “clase” ya que el primero  corresponde al nombre del animal (es distinto para cada uno) y “clase” es la especie a la que pertenece. Pruebe diferentes valores de K. Evalúe los resultados obtenidos en cada caso  observando los valores de los índices Silhouette e Inercia. Analice los clusters obtenidos. Observe cómo fueron repartidos los animales en cada uno de los clusters prestando atención a los atributos “animal” y “clase” no tenidos en cuenta al momento de agrupar.



Nota: El archivo se encuentra en la carpeta de drive
"""

import pandas as pd

# load the training dataset
from google.colab import drive
drive.mount('/content/drive')
pathCurso = '/content/drive/MyDrive/AP_UNdeC/Data/'
ruta_archivo = pathCurso + "Zoo.csv"


df = pd.read_csv(ruta_archivo, encoding = "latin1")
df.head()

mask = df['Clase'] == 'Reptil'
df[mask].shape

import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Cargar el conjunto de datos


# Extraer las columnas relevantes para la agrupación
X = df.drop(['animal', 'Clase'], axis=1)

# Estandarizar las características para mejorar el rendimiento del algoritmo K-means
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Definir el modelo K-means con el número de clusters deseado
num_clusters = 7  # Puedes ajustar este valor según tu necesidad
kmeans_model = KMeans(n_clusters=num_clusters, random_state=42)

# Aplicar K-means al conjunto de datos estandarizado
df['cluster'] = kmeans_model.fit_predict(X_scaled)

# Visualizar los resultados (opcional)
plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=df['cluster'], cmap='viridis', marker='o', edgecolors='w', alpha=0.7)
plt.title('Agrupación con K-means')
plt.xlabel('Característica 1 (Ejemplo)')
plt.ylabel('Característica 2 (Ejemplo)')
plt.show()

# Imprimir el resultado de la agrupación
print(df[['animal', 'Clase', 'cluster']])

import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

# Cargar el conjunto de datos


# Extraer las columnas relevantes para la agrupación
X = df.drop(['animal', 'Clase'], axis=1)

# Estandarizar las características para mejorar el rendimiento del algoritmo K-means
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Definir una lista de valores de K que quieres probar
k_values = [2, 3, 4, 5, 6, 7, 8, 9, 10]

# Almacenar resultados de índices Silhouette e Inercia
silhouette_scores = []
inertia_scores = []

# Bucle sobre diferentes valores de K
for k in k_values:
    # Definir el modelo K-means con el número de clusters deseado
    kmeans_model = KMeans(n_clusters=k, random_state=42)

    # Aplicar K-means al conjunto de datos estandarizado
    df['cluster'] = kmeans_model.fit_predict(X_scaled)

    # Calcular y almacenar el índice Silhouette
    silhouette = silhouette_score(X_scaled, df['cluster'])
    silhouette_scores.append(silhouette)

    # Almacenar la inercia (suma de distancias cuadradas dentro del cluster)
    inertia_scores.append(kmeans_model.inertia_)

# Visualizar los resultados
plt.figure(figsize=(12, 4))

# Gráfico de Silhouette
plt.subplot(1, 2, 1)
plt.plot(k_values, silhouette_scores, marker='o')
plt.title('Índice Silhouette para diferentes valores de K')
plt.xlabel('Número de clusters (K)')
plt.ylabel('Silhouette Score')

# Gráfico de Inercia
plt.subplot(1, 2, 2)
plt.plot(k_values, inertia_scores, marker='o')
plt.title('Inercia para diferentes valores de K')
plt.xlabel('Número de clusters (K)')
plt.ylabel('Inercia')

plt.tight_layout()
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

# Cargar el conjunto de datos


# Definir las características (X) y la variable objetivo (y)
X = df.drop(['animal', 'Clase'], axis=1)
y = df['Clase']

# Dividir el conjunto de datos en entrenamiento y prueba con estratificación y una semilla de aleatoriedad de 0
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=0)

# Estandarizar las características (opcional pero a menudo beneficioso para modelos lineales)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Crear un modelo de regresión logística con una semilla de aleatoriedad de 50
logistic_model = LogisticRegression(random_state=50)

# Entrenar el modelo en los datos de entrenamiento
logistic_model.fit(X_train_scaled, y_train)

# Realizar predicciones en los datos de prueba
y_pred = logistic_model.predict(X_test_scaled)

# Evaluar la precisión del modelo en los datos de prueba
accuracy = accuracy_score(y_test, y_pred)
print(f'Precisión del modelo de regresión logística: {accuracy:.4f}')

# Contar la cantidad total de mamíferos en el conjunto de datos de prueba
total_mamiferos = (y_test == 'Mamifero').sum()

# Contar la cantidad de mamíferos clasificados correctamente
correctly_classified_mamiferos = ((y_test == 'Mamifero') & (y_pred == 'Mamifero')).sum()

# Verificar la afirmación
afirmacion_verdadera = correctly_classified_mamiferos == 13

print(f'El modelo clasificó correctamente a {correctly_classified_mamiferos} mamíferos de un total de {total_mamiferos}.')
print(f'La afirmación es: {afirmacion_verdadera}')

from sklearn.metrics import recall_score

# Calcular el F1-score para la clase 'Reptile' en el conjunto de datos de prueba
recall_reptiles = recall_score(y_test == 'Invertebrado', y_pred == 'Invertebrado')

# Verificar la afirmación
afirmacion_verdadera = recall_reptiles == 0.67  # Reemplaza 0.5 con el valor correcto

print(f'El F1-score para la clase "Reptile" es: {recall_reptiles:.4f}')
print(f'La afirmación es: {afirmacion_verdadera}')

from sklearn.metrics import f1_score, recall

# Calcular el F1-score para la clase 'Reptile' en el conjunto de datos de prueba
f1_score_reptiles = f1_score(y_test == 'Reptil', y_pred == 'Reptil')

# Verificar la afirmación
afirmacion_verdadera = f1_score_reptiles == 0.5  # Reemplaza 0.5 con el valor correcto

print(f'El F1-score para la clase "Reptile" es: {f1_score_reptiles:.4f}')
print(f'La afirmación es: {afirmacion_verdadera}')

# Contar la cantidad total de mamíferos en el conjunto de datos de prueba
total_reptil = (y_test == 'Reptil').sum()

# Contar la cantidad de mamíferos clasificados correctamente
correctly_classified_reptil = ((y_test == 'Reptil') & (y_pred == 'Reptil')).sum()

# Verificar la afirmación
afirmacion_verdadera = correctly_classified_reptil == 2

print(f'El modelo clasificó correctamente a {correctly_classified_reptil} reptiles de un total de {total_reptil}.')
print(f'La afirmación es: {afirmacion_verdadera}')

mask1 = y_pred == 'Reptil'
y_pred[mask1]

from sklearn.metrics import f1_score

# Calcular el F1-score promedio ponderado en el conjunto de datos de prueba
f1_score_promedio_ponderado = f1_score(y_test, y_pred, average='weighted')

# Verificar la afirmación
afirmacion_verdadera = f1_score_promedio_ponderado == 0.88  # Reemplaza 0.88 con el valor correcto

print(f'El F1-score promedio ponderado es: {f1_score_promedio_ponderado:.4f}')
print(f'La afirmación es: {afirmacion_verdadera}')