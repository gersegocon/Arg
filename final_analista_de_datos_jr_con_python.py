# -*- coding: utf-8 -*-
"""Final Analista de datos Jr con Python

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FjTioc0jL2vfRTi4oi17dj-yCWZtQMZP
"""

import pandas as pd

# load the training dataset
from google.colab import drive
drive.mount('/content/drive')
pathCurso = '/content/drive/MyDrive/AP_UNdeC/Data/'
ruta_archivo = pathCurso + "winemag-data-130k-v2.csv"


datos = pd.read_csv(ruta_archivo)
datos.head()

"""Manipulación de los datos

Asumiendo que en datos, tienes almacenado los datos del DataFrame original, sin alteraciones, ejecuta el siguiente comando, para generar una copia del DataFrame:

datos_copy = datos.copy(deep = True)


Luego, elimina las columnas:


region_2
taster_twitter_handle
designation
Unnamed: 0

Ahora, elimina todos los valores ausentes, considerando las filas.


Por último, codifica las variables categóricas mediante una codificación de etiquetas.


Utiliza el siguiente fragmento de código para trabajar en tu conjunto de datos:



features = ['price', 'points', 'province', 'region_1','taster_name','variety', 'winery']

target = 'country'
"""

datos_copy = datos.copy(deep = True)

datos_copy.drop(['region_2', 'designation', 'taster_twitter_handle', 'Unnamed: 0'], axis=1, inplace = True)

datos_copy.dropna(axis=0, inplace = True)
datos_copy.reset_index(inplace = True)
datos_copy.drop('index', axis=1, inplace = True)

"""Crea un Árbol de Decisión para poder clasificar los países de las referencias de vinos, en base a las features mencionadas.
Ten en cuenta dividir el conjunto de datos, en un 70/30 con una semilla de aleatoriedad igual a 17.
Para el árbol, también establece el mismo valor de semilla, y el nivel máximo en 8.
"""

from sklearn.metrics import f1_score
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier

datos_copy2 = datos_copy.copy()
# Inicializar el codificador de etiquetas
label_encoder = LabelEncoder()


# Codificar las variables categóricas en el DataFrame seleccionado
for column in datos_copy2.select_dtypes(['object']).columns:
  datos_copy2[column] = label_encoder.fit_transform(datos_copy2[column])

features = ['price', 'points', 'province', 'region_1','taster_name','variety', 'winery']
target = 'country'

x = datos_copy2[features]
y = datos_copy2[target]

# Dividir el conjunto de datos en entrenamiento y prueba (70/30) con una semilla de aleatoriedad
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=17)

# Asegurarse de que las etiquetas del conjunto de prueba sean numéricas
y_train_encoded = label_encoder.fit_transform(y_train)
y_test_encoded = label_encoder.transform(y_test)

# Inicializar el modelo de Árbol de Decisión
tree_model = DecisionTreeClassifier(random_state=17, max_depth=8)

# Entrenar el modelo con el conjunto de entrenamiento
tree_model.fit(X_train, y_train_encoded)

# Realizar predicciones en el conjunto de prueba
y_pred = predictions = tree_model.predict(X_test)

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

# Ver las correspondencias entre las etiquetas originales y las etiquetas numéricas
correspondencias = dict(zip(datos_copy['country'], y))

# Imprimir el resultado
for etiqueta_original, etiqueta_numerica in correspondencias.items():
    print(f"Etiqueta original '{etiqueta_original}' corresponde a la etiqueta numérica: {etiqueta_numerica}")

from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test_encoded, predictions)
print("Valor de accuracy: ", accuracy*100)

from sklearn.metrics import confusion_matrix

# Obtener la matriz de confusión
conf_matrix = confusion_matrix(y_test, y_pred, labels=label_encoder.classes_)

# Encontrar el índice correspondiente a la clase "Spain" en las clases de LabelEncoder
spain_index = 5
# Contar las predicciones incorrectas para la clase "Spain"
incorrect_predictions_spain = sum(conf_matrix[spain_index, :]) - conf_matrix[spain_index, spain_index]

# Imprimir el resultado
print(f"Número de predicciones incorrectas para la clase 'Spain': {incorrect_predictions_spain}")

from sklearn.neural_network import MLPClassifier

# Inicializar el modelo MLP
mlp_model = MLPClassifier(hidden_layer_sizes=(6, 12), max_iter=100, random_state=17)

# Entrenar el modelo con el conjunto de entrenamiento
mlp_model.fit(X_train, y_train)

# Realizar predicciones en el conjunto de prueba
y_pred = mlp_model.predict(X_test)

# Calcular la precisión del modelo
accuracy = accuracy_score(y_test, y_pred)
print(f"Precisión del modelo MLP: {accuracy * 100}%")

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

from sklearn.neural_network import MLPClassifier

# Inicializar el modelo MLP con 100 neuronas en la primera capa y 200 en la segunda
mlp_model_large = MLPClassifier(hidden_layer_sizes=(100, 200), max_iter=100, random_state=17)

# Entrenar el modelo con el conjunto de entrenamiento
mlp_model_large.fit(X_train, y_train)

# Realizar predicciones en el conjunto de prueba
y_pred_large = mlp_model_large.predict(X_test)

# Calcular la precisión del modelo
accuracy_large = accuracy_score(y_test, y_pred_large)

# Calcular la diferencia en valor absoluto del accuracy con la primera versión del MLP
diferencia_absoluta = abs(accuracy_large - accuracy)
print(f"Diferencia en valor absoluto del Accuracy: {diferencia_absoluta}")
print(accuracy_large)
print(accuracy)

print(classification_report(y_test, y_pred_large))

"""**Manipulación de los datos**

Asumiendo que en datos, tienes almacenado los datos del DataFrame original, sin alteraciones, ejecuta el siguiente comando, para
generar una copia del DataFrame:

datos_copy = datos.copy(deep = True)

Luego, elimina las columnas:

region_2

taster_twitter_handle

designation

Unnamed: 0

Ahora por último, completa:

Con el valor de la Mediana para el campo 'points'

Con el valor de la Media para el campo 'price'

Ahora, elimina todos los valores ausentes, considerando las filas.
"""

datos_copy = datos.copy(deep = True)
datos_copy.drop(['region_2','taster_twitter_handle','designation','Unnamed: 0'],axis=1,inplace=True)
datos_copy

mediana_points = datos_copy['points'].median()
media_price = datos_copy['price'].mean()
datos_copy['points'].fillna(mediana_points, inplace = True)
datos_copy['price'].fillna(media_price, inplace = True
                           )

datos_copy.dropna(axis=0, inplace = True)
datos_copy.reset_index(inplace = True)
datos_copy.drop('index', axis=1, inplace = True)

"""Por último, codifica las variables categóricas mediante una codificación de etiquetas.
Utiliza el siguiente fragmento de código para trabajar en tu conjunto de datos:

features = ['country', 'points', 'province', 'region_1','taster_name','variety', 'winery']

target = 'price'

Ten en cuenta que todas las siguientes preguntas serán en base a la realización de los pasos anteriores
"""

from sklearn.preprocessing import LabelEncoder

datos_copy2 = datos_copy.copy()
# Inicializar el codificador de etiquetas
label_encoder = LabelEncoder()

# Codificar las variables categóricas en el DataFrame seleccionado
for column in datos_copy2.select_dtypes(['object']).columns:
  datos_copy2[column] = label_encoder.fit_transform(datos_copy2[column])

features = ['price', 'points', 'province', 'region_1','taster_name','variety', 'winery']
target = 'country'

x = datos_copy2[features]
y = datos_copy2[target]

"""Considerando dividir el conjunto de datos en 70/30, con una semilla de aleatoriedad de 17.
Creando un MLP Regresor con 1 capa oculta de 100 neuronas, 1000 iteraciones como máximo, un valor de 0.001 de alpha y una
semilla de de aleatoriedad de 17:
"""

from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error

# Dividir el conjunto de datos en entrenamiento y prueba (70/30) con una semilla de aleatoriedad
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=17)

# Inicializar el modelo MLP Regresor con 1 capa oculta de 100 neuronas
mlp_regressor = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, alpha=0.001, random_state=17)

# Entrenar el modelo con el conjunto de entrenamiento
mlp_regressor.fit(X_train, y_train)

# Realizar predicciones en el conjunto de prueba
y_pred = mlp_regressor.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
print(f"Error absoluto medio (MAE): {mae}")
print(f"Error cuadratico medio (MSE): {mse}")

from sklearn.metrics import r2_score
r2 = r2_score(y_test, y_pred)

print("R2: ",r2)

# Dividir el conjunto de datos en entrenamiento y prueba (70/30) con una semilla de aleatoriedad
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=17)

# Inicializar el modelo MLP Regresor con 1 capa oculta de 100 neuronas
mlp_regressor = MLPRegressor(hidden_layer_sizes=(100,250), max_iter=100, alpha=0.0001, random_state=17)

# Entrenar el modelo con el conjunto de entrenamiento
mlp_regressor.fit(X_train, y_train)

# Realizar predicciones en el conjunto de prueba
y_pred = mlp_regressor.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
print(f"Error absoluto medio (MAE): {mae}")
print(f"Error cuadratico medio (MSE): {mse}")

from sklearn.metrics import r2_score
r2 = r2_score(y_test, y_pred)

print("R2: ",r2)